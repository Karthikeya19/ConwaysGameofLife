{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-Specialization-Supervised-Learning-HW-2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthikeya19/ConwaysGameofLife/blob/master/ML_Specialization_Supervised_Learning_HW_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xIaEwCD406A"
      },
      "source": [
        "# Supervised Learning: Homework 2#\n",
        "\n",
        "This homework will aid in your understanding of the Perceptron Algorithm by having you:\n",
        "- practice applying the perceptron algorithm to toy data\n",
        "- implement the perceptron algorithm and one of its variants\n",
        "- apply your perceptron implementation on larger, more interesting data sets\n",
        "\n",
        "The following are some numpy functions that maybe useful for this assignment:\n",
        "1. np.sum with axis argument\n",
        "2. Comparing matrices of different dimensions / advanced np.sum\n",
        "3. np.sign\n",
        "4. np.argmax\n",
        "5. np.reshape\n",
        "6. np.array_split, look at the axis argument\n",
        "7. np.concatenate, look at the axis argument\n",
        "8. np.zeros\n",
        "9. numpy.ndarray.shape\n",
        "10. numpy logic functions e.g. np.array([[1, 2],[3, 4]]) == 3\n",
        "\n",
        "Further details about numpy functions can be found at the numpy documentation (https://numpy.org/doc/stable/reference/index.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YM-_zLf9Bp-"
      },
      "source": [
        "# Imports\n",
        "import itertools\n",
        "import operator\n",
        "import pdb\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib import colors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzxm6i6DudDo"
      },
      "source": [
        "Utility functions for vector manipulation and score computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z1zuhqltjBy"
      },
      "source": [
        "def cv(value_list):\n",
        "    \"\"\"\n",
        "    Takes a list of numbers and returns a column vector:  n x 1\n",
        "    \"\"\"\n",
        "    \n",
        "    return np.transpose(rv(value_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdSQerHOuqA1"
      },
      "source": [
        "def rv(value_list):\n",
        "    \"\"\"\n",
        "    Takes a list of numbers and returns a row vector: 1 x n\n",
        "    \"\"\"\n",
        "    \n",
        "    return np.array([value_list])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHYx8lvtxZb-"
      },
      "source": [
        "def y(x, th, th0):\n",
        "    \"\"\"\n",
        "    x is dimension d by 1\n",
        "    th is dimension d by 1\n",
        "    th0 is a scalar\n",
        "    return a 1 by 1 matrix\n",
        "    \"\"\"\n",
        "    \n",
        "    return np.dot(np.transpose(th), x) + th0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8pxUaDhxe2d"
      },
      "source": [
        "def positive(x, th, th0):\n",
        "    \"\"\"\n",
        "    x is dimension d by 1\n",
        "    th is dimension d by 1\n",
        "    th0 is dimension 1 by 1\n",
        "    return 1 by 1 matrix of +1, 0, -1\n",
        "    \"\"\"\n",
        "    \n",
        "    return np.sign(y(x, th, th0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4nApqvwxpQn"
      },
      "source": [
        "def score(data, labels, th, th0):\n",
        "    \"\"\"\n",
        "    data is dimension d by n\n",
        "    labels is dimension 1 by n\n",
        "    ths is dimension d by 1\n",
        "    th0s is dimension 1 by 1\n",
        "    return 1 by 1 matrix of integer indicating number of data points correct for\n",
        "    each separator.\n",
        "    \"\"\"\n",
        "    \n",
        "    return np.sum(positive(data, th, th0) == labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7xU6BWKypIb"
      },
      "source": [
        "Utility functions for plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVjpG0NeytYH"
      },
      "source": [
        "def tidy_plot(xmin,\n",
        "              xmax,\n",
        "              ymin,\n",
        "              ymax,\n",
        "              center=False,\n",
        "              title=None,\n",
        "              xlabel=None,\n",
        "              ylabel=None):\n",
        "    \"\"\"\n",
        "    Set up axes for plotting\n",
        "    xmin, xmax, ymin, ymax = (float) plot extents\n",
        "    Return matplotlib axes\n",
        "    \"\"\"\n",
        "    plt.ion()\n",
        "    plt.figure(facecolor=\"white\")\n",
        "    ax = plt.subplot()\n",
        "    if center:\n",
        "        ax.spines['left'].set_position('zero')\n",
        "        ax.spines['right'].set_color('none')\n",
        "        ax.spines['bottom'].set_position('zero')\n",
        "        ax.spines['top'].set_color('none')\n",
        "        ax.spines['left'].set_smart_bounds(True)\n",
        "        ax.spines['bottom'].set_smart_bounds(True)\n",
        "        ax.xaxis.set_ticks_position('bottom')\n",
        "        ax.yaxis.set_ticks_position('left')\n",
        "    else:\n",
        "        ax.spines[\"top\"].set_visible(False)\n",
        "        ax.spines[\"right\"].set_visible(False)\n",
        "        ax.get_xaxis().tick_bottom()\n",
        "        ax.get_yaxis().tick_left()\n",
        "    eps = .05\n",
        "    plt.xlim(xmin - eps, xmax + eps)\n",
        "    plt.ylim(ymin - eps, ymax + eps)\n",
        "    if title: ax.set_title(title)\n",
        "    if xlabel: ax.set_xlabel(xlabel)\n",
        "    if ylabel: ax.set_ylabel(ylabel)\n",
        "    \n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-Hpy0F7y4dO"
      },
      "source": [
        "def plot_separator(ax, th, th_0):\n",
        "    \"\"\"\n",
        "    Plot separator in 2D\n",
        "    ax = (matplotlib plot) plot axis\n",
        "    th = (numpy array) theta\n",
        "    th_0 = (float) theta_0\n",
        "    \"\"\"\n",
        "    xmin, xmax = ax.get_xlim()\n",
        "    ymin, ymax = ax.get_ylim()\n",
        "    pts = []\n",
        "    eps = 1.0e-6\n",
        "    # xmin boundary crossing is when xmin th[0] + y th[1] + th_0 = 0\n",
        "    # that is, y = (-th_0 - xmin th[0]) / th[1]\n",
        "    if abs(th[1, 0]) > eps:\n",
        "        pts += [np.array([x, (-th_0 - x * th[0,0]) / th[1,0]]) \\\n",
        "                                                        for x in (xmin, xmax)]\n",
        "    if abs(th[0, 0]) > 1.0e-6:\n",
        "        pts += [np.array([(-th_0 - y * th[1,0]) / th[0,0], y]) \\\n",
        "                                                         for y in (ymin, ymax)]\n",
        "    in_pts = []\n",
        "    for p in pts:\n",
        "        if (xmin-eps) <= p[0] <= (xmax+eps) and \\\n",
        "           (ymin-eps) <= p[1] <= (ymax+eps):\n",
        "            duplicate = False\n",
        "            for p1 in in_pts:\n",
        "                if np.max(np.abs(p - p1)) < 1.0e-6:\n",
        "                    duplicate = True\n",
        "            if not duplicate:\n",
        "                in_pts.append(p)\n",
        "    if in_pts and len(in_pts) >= 2:\n",
        "        # Plot separator\n",
        "        vpts = np.vstack(in_pts)\n",
        "        ax.plot(vpts[:, 0], vpts[:, 1], 'k-', lw=2)\n",
        "        # Plot normal\n",
        "        vmid = 0.5 * (in_pts[0] + in_pts[1])\n",
        "        scale = np.sum(th * th)**0.5\n",
        "        diff = in_pts[0] - in_pts[1]\n",
        "        dist = max(xmax - xmin, ymax - ymin)\n",
        "        vnrm = vmid + (dist / 10) * (th.T[0] / scale)\n",
        "        vpts = np.vstack([vmid, vnrm])\n",
        "        ax.plot(vpts[:, 0], vpts[:, 1], 'k-', lw=2)\n",
        "        # Try to keep limits from moving around\n",
        "        ax.set_xlim((xmin, xmax))\n",
        "        ax.set_ylim((ymin, ymax))\n",
        "    else:\n",
        "        print('Separator not in plot range')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVa4JLBpzAXg"
      },
      "source": [
        "def plot_data(data,\n",
        "              labels,\n",
        "              ax=None,\n",
        "              clear=False,\n",
        "              xmin=None,\n",
        "              xmax=None,\n",
        "              ymin=None,\n",
        "              ymax=None):\n",
        "    \"\"\"\n",
        "    Make scatter plot of data.\n",
        "    data = (numpy array)\n",
        "    ax = (matplotlib plot)\n",
        "    clear = (bool) clear current plot first\n",
        "    xmin, xmax, ymin, ymax = (float) plot extents\n",
        "    returns matplotlib plot on ax\n",
        "    \"\"\"\n",
        "    if ax is None:\n",
        "        if xmin == None: xmin = np.min(data[0, :]) - 0.5\n",
        "        if xmax == None: xmax = np.max(data[0, :]) + 0.5\n",
        "        if ymin == None: ymin = np.min(data[1, :]) - 0.5\n",
        "        if ymax == None: ymax = np.max(data[1, :]) + 0.5\n",
        "        ax = tidy_plot(xmin, xmax, ymin, ymax)\n",
        "\n",
        "        x_range = xmax - xmin\n",
        "        y_range = ymax - ymin\n",
        "        if .1 < x_range / y_range < 10:\n",
        "            ax.set_aspect('equal')\n",
        "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
        "    elif clear:\n",
        "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
        "        ax.clear()\n",
        "    else:\n",
        "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
        "    colors = np.choose(labels > 0, cv(['r', 'g']))[0]\n",
        "    ax.scatter(data[0, :],\n",
        "               data[1, :],\n",
        "               c=colors,\n",
        "               marker='o',\n",
        "               s=50,\n",
        "               edgecolors='none')\n",
        "    # Seems to occasionally mess up the limits\n",
        "    ax.set_xlim(xlim)\n",
        "    ax.set_ylim(ylim)\n",
        "    ax.grid(True, which='both')\n",
        "    #ax.axhline(y=0, color='k')\n",
        "    #ax.axvline(x=0, color='k')\n",
        "    \n",
        "    return ax\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF8sBm5-zH02"
      },
      "source": [
        "def plot_nonlin_sep(predictor,\n",
        "                    ax=None,\n",
        "                    xmin=None,\n",
        "                    xmax=None,\n",
        "                    ymin=None,\n",
        "                    ymax=None,\n",
        "                    res=30):\n",
        "    \"\"\"\n",
        "    Must either specify limits or existing ax\n",
        "    Shows matplotlib plot on ax\n",
        "    \"\"\"\n",
        "    if ax is None:\n",
        "        ax = tidy_plot(xmin, xmax, ymin, ymax)\n",
        "    else:\n",
        "        if xmin == None:\n",
        "            xmin, xmax = ax.get_xlim()\n",
        "            ymin, ymax = ax.get_ylim()\n",
        "        else:\n",
        "            ax.set_xlim((xmin, xmax))\n",
        "            ax.set_ylim((ymin, ymax))\n",
        "\n",
        "    cmap = colors.ListedColormap(['black', 'white'])\n",
        "    bounds = [-2, 0, 2]\n",
        "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "    ima = np.array([[predictor(x1i, x2i) \\\n",
        "                         for x1i in np.linspace(xmin, xmax, res)] \\\n",
        "                         for x2i in np.linspace(ymin, ymax, res)])\n",
        "    im = ax.imshow(np.flipud(ima),\n",
        "                   interpolation='none',\n",
        "                   extent=[xmin, xmax, ymin, ymax],\n",
        "                   cmap=cmap,\n",
        "                   norm=norm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0NrK741zOhH"
      },
      "source": [
        "Datasets and utility functions for generating datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZYlwkHTzS8d"
      },
      "source": [
        "def super_simple_separable_through_origin():\n",
        "    \"\"\"\n",
        "    Return d = 2 by n = 4 data matrix and 1 x n = 4 label matrix\n",
        "    \"\"\"\n",
        "    X = np.array([[2, 3, 9, 12], [5, 1, 6, 5]])\n",
        "    y = np.array([[1, -1, 1, -1]])\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt_MYx_8zYr4"
      },
      "source": [
        "def super_simple_separable():\n",
        "    \"\"\"\n",
        "    Return d = 2 by n = 4 data matrix and 1 x n = 4 label matrix\n",
        "    \"\"\"\n",
        "    X = np.array([[2, 3, 9, 12], [5, 2, 6, 5]])\n",
        "    y = np.array([[1, -1, 1, -1]])\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLub3inJzdPd"
      },
      "source": [
        "def xor():\n",
        "    \"\"\"\n",
        "    Return d = 2 by n = 4 data matrix and 1 x n = 4 label matrix\n",
        "    \"\"\"\n",
        "    X = np.array([[1, 2, 1, 2], [1, 2, 2, 1]])\n",
        "    y = np.array([[1, 1, -1, -1]])\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR2-aCI9zi47"
      },
      "source": [
        "def xor_more():\n",
        "    \"\"\"\n",
        "    Return d = 2 by n = 4 data matrix and 1 x n = 4 label matrix\n",
        "    \"\"\"\n",
        "    X = np.array([[1, 2, 1, 2, 2, 4, 1, 3], [1, 2, 2, 1, 3, 1, 3, 3]])\n",
        "    y = np.array([[1, 1, -1, -1, 1, 1, -1, -1]])\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n4RksV8zocG"
      },
      "source": [
        "# Test data 1\n",
        "data1, labels1, data2, labels2 = \\\n",
        "(np.array([[-2.97797707,  2.84547604,  3.60537239, -1.72914799, -2.51139524,\n",
        "         3.10363716,  2.13434789,  1.61328413,  2.10491257, -3.87099125,\n",
        "         3.69972003, -0.23572183, -4.19729119, -3.51229538, -1.75975746,\n",
        "        -4.93242615,  2.16880073, -4.34923279, -0.76154262,  3.04879591,\n",
        "        -4.70503877,  0.25768309,  2.87336016,  3.11875861, -1.58542576,\n",
        "        -1.00326657,  3.62331703, -4.97864369, -3.31037331, -1.16371314],\n",
        "       [ 0.99951218, -3.69531043, -4.65329654,  2.01907382,  0.31689211,\n",
        "         2.4843758 , -3.47935105, -4.31857472, -0.11863976,  0.34441625,\n",
        "         0.77851176,  1.6403079 , -0.57558913, -3.62293005, -2.9638734 ,\n",
        "        -2.80071438,  2.82523704,  2.07860509,  0.23992709,  4.790368  ,\n",
        "        -2.33037832,  2.28365246, -1.27955206, -0.16325247,  2.75740801,\n",
        "         4.48727808,  1.6663558 ,  2.34395397,  1.45874837, -4.80999977]]),\n",
        "   np.array([[-1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,\n",
        "        -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
        "        -1., -1., -1., -1.]]), np.array([[ 0.6894022 , -4.34035772,  3.8811067 ,  4.29658177,  1.79692041,\n",
        "         0.44275816, -3.12150658,  1.18263462, -1.25872232,  4.33582168,\n",
        "         1.48141202,  1.71791177,  4.31573568,  1.69988085, -2.67875489,\n",
        "        -2.44165649, -2.75008176, -4.19299345, -3.15999758,  2.24949368,\n",
        "         4.98930636, -3.56829885, -2.79278501, -2.21547048,  2.4705776 ,\n",
        "         4.80481986,  2.77995092,  1.95142828,  4.48454942, -4.22151738],\n",
        "       [-2.89934727,  1.65478851,  2.99375325,  1.38341854, -4.66701003,\n",
        "        -2.14807131, -4.14811829,  3.75270334,  4.54721208,  2.28412663,\n",
        "        -4.74733482,  2.55610647,  3.91806508, -2.3478982 ,  4.31366925,\n",
        "        -0.92428271, -0.84831235, -3.02079092,  4.85660032, -1.86705397,\n",
        "        -3.20974025, -4.88505017,  3.01645974,  0.03879148, -0.31871427,\n",
        "         2.79448951, -2.16504256, -3.91635569,  3.81750006,  4.40719702]]),\n",
        "   np.array([[-1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
        "        -1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
        "        -1.,  1.,  1.,  1.]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9W6RsMfzrmq"
      },
      "source": [
        "# Test data 2\n",
        "big_data, big_data_labels = (np.array(\n",
        "    [[\n",
        "        -2.04297103, -1.85361169, -2.65467827, -1.23013149, -0.31934782,\n",
        "        1.33112127, 2.3297942, 1.47705445, -1.9733787, -2.35476882,\n",
        "        -4.97193554, 3.49851995, 4.00302943, 0.83369183, 0.41371989,\n",
        "        4.37614714, 1.03536965, 1.2354608, -0.7933465, -3.85456759, 3.22134658,\n",
        "        -3.39787483, -1.31182253, -2.61363628, -1.14618119, -0.2174626,\n",
        "        1.32549116, 2.54520221, 0.31565661, 2.24648287, -3.33355258,\n",
        "        -0.98689271, -0.24876636, -3.16008017, 1.22353111, 4.77766994,\n",
        "        -1.81670773, -3.58939471, -2.16268851, 2.88028351, -3.42297827,\n",
        "        -2.74992813, -0.40293356, -3.45377267, 0.62400624, -0.35794507,\n",
        "        -4.1648704, -1.08734116, 0.22367444, 1.09067619, 1.28738004,\n",
        "        2.07442478, 4.61951855, 4.47029706, 2.86510481, 4.12532285, 0.48170777,\n",
        "        0.60089857, 4.50287515, 2.95549453, 4.22791451, -1.28022286,\n",
        "        2.53126681, 2.41887277, -4.9921717, 4.15022718, 0.49670572, 2.0268248,\n",
        "        -4.63475897, -4.20528418, 1.77013481, -3.45389325, 1.0238472,\n",
        "        -1.2735185, 4.75384686, 1.32622048, -0.13092625, 1.23457116,\n",
        "        -1.69515197, 2.82027615, -1.01140935, 3.36451016, 4.43762708,\n",
        "        -4.2679604, 4.76734154, -4.14496071, -4.38737405, -1.13214501,\n",
        "        -2.89008477, 3.22986894, 1.84103699, -3.91906092, -2.8867831,\n",
        "        2.31059245, -3.62773189, -4.58459406, -4.06343392, -3.10927054,\n",
        "        1.09152472, 2.99896855\n",
        "    ],\n",
        "     [\n",
        "         -2.1071566, -3.06450052, -3.43898434, 0.71320285, 1.51214693,\n",
        "         4.14295175, 4.73681233, -2.80366981, 1.56182223, 0.07061724,\n",
        "         -0.92053415, -3.61953464, 0.39577344, -3.03202474, -4.90408303,\n",
        "         -0.10239158, -1.35546287, 1.31372748, -1.97924525, -3.72545813,\n",
        "         1.84834303, -0.13679709, 1.36748822, -2.92886952, -2.48367819,\n",
        "         -0.0894489, -2.99090327, 0.35494698, 0.94797491, 4.20393035,\n",
        "         -3.14009852, -4.86292242, 3.2964068, -0.9911453, 4.39465, 3.64956975,\n",
        "         -0.72225648, -0.15864119, -2.0340774, -4.00758749, 0.8627915,\n",
        "         3.73237594, -0.70011824, 1.07566463, -4.05063547, -3.98137177,\n",
        "         4.82410619, 2.5905222, 0.34188269, -1.44737803, 3.27583966,\n",
        "         2.06616486, -4.43584161, 0.27795053, 4.37207651, -4.48564119,\n",
        "         0.7183541, 1.59374552, -0.13951634, 0.67825519, -4.02423434,\n",
        "         4.15893861, -1.52110278, 2.1320374, 3.31118893, -4.04072252,\n",
        "         2.41403912, -1.04635499, 3.39575642, 2.2189097, 4.78827245,\n",
        "         1.19808069, 3.10299723, 0.18927394, 0.14437543, -4.17561642,\n",
        "         0.6060279, 0.22693751, -3.39593567, 1.14579319, 3.65449494,\n",
        "         -1.27240159, 0.73111639, 3.48806017, 2.48538719, -1.83892096,\n",
        "         1.42819622, -1.37538641, 3.4022984, 0.82757044, -3.81792516,\n",
        "         2.77707152, -1.49241173, 2.71063994, -3.33495679, -4.00845675,\n",
        "         0.719904, -2.3257032, 1.65515972, -1.90859948\n",
        "     ]]),\n",
        "      np.array([[\n",
        "          -1., -1., -1., 1., 1., -1., 1., -1., 1., -1.,\n",
        "          -1., -1., 1., 1., -1., 1., -1., -1., -1., 1.,\n",
        "          -1., -1., 1., -1., 1., -1., -1., 1., 1., -1.,\n",
        "          -1., -1., 1., -1., 1., 1., 1., -1., -1., 1.,\n",
        "          -1., 1., -1., 1., -1., 1., 1., 1., 1., -1.,\n",
        "          1., 1., -1., 1., 1., -1., -1., 1., 1., 1.,\n",
        "          -1., 1., 1., -1., -1., 1., 1., 1., 1., -1.,\n",
        "          1., -1., 1., -1., -1., -1., 1., 1., -1., 1.,\n",
        "          1., 1., 1., -1., -1., 1., -1., -1., -1., 1.,\n",
        "          -1., -1., -1., 1., -1., -1., -1., -1., 1., 1.\n",
        "      ]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeG0_is6z_mL"
      },
      "source": [
        "def gen_big_data():\n",
        "    \"\"\"\n",
        "    Return method that generates a dataset of input size n of X, y drawn from big_data\n",
        "    \"\"\"\n",
        "    nd = big_data.shape[1]\n",
        "    current = [0]\n",
        "\n",
        "    def f(n):\n",
        "        cur = current[0]\n",
        "        vals = big_data[:, cur:cur + n], big_data_labels[:, cur:cur + n]\n",
        "        current[0] += n\n",
        "        if current[0] >= nd: current[0] = 0\n",
        "        return vals\n",
        "\n",
        "    return f\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pinx_rk60DeW"
      },
      "source": [
        "def gen_lin_separable(num_points=20,\n",
        "                      th=np.array([[3], [4]]),\n",
        "                      th_0=np.array([[0]]),\n",
        "                      dim=2):\n",
        "    \"\"\"\n",
        "    Generate linearly separable dataset X, y given theta and theta0\n",
        "    Return X, y where\n",
        "    X is a numpy array where each column represents a dim-dimensional data point\n",
        "    y is a column vector of 1s and -1s\n",
        "    \"\"\"\n",
        "    X = np.random.uniform(low=-5, high=5, size=(dim, num_points))\n",
        "    y = np.sign(np.dot(np.transpose(th), X) + th_0)\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnrUkXbi0LFG"
      },
      "source": [
        "def big_higher_dim_separable():\n",
        "    X, y = gen_lin_separable(num_points=50,\n",
        "                             dim=6,\n",
        "                             th=np.array([[3], [4], [2], [1], [0], [3]]))\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzkKFtrx0N8F"
      },
      "source": [
        "def gen_flipped_lin_separable(num_points=20,\n",
        "                              pflip=0.25,\n",
        "                              th=np.array([[3], [4]]),\n",
        "                              th_0=np.array([[0]]),\n",
        "                              dim=2):\n",
        "    \"\"\"\n",
        "    Generate difficult (usually not linearly separable) data sets by\n",
        "    \"flipping\" labels with some probability.\n",
        "    Return method which takes num_points and flips labels with pflip\n",
        "    \"\"\"\n",
        "    def flip_generator(num_points=20):\n",
        "        X, y = gen_lin_separable(num_points, th, th_0, dim)\n",
        "        flip = np.random.uniform(low=0, high=1, size=(num_points, ))\n",
        "        for i in range(num_points):\n",
        "            if flip[i] < pflip: y[0, i] = -y[0, i]\n",
        "        return X, y\n",
        "\n",
        "    return flip_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_2Lr-1z0vPI"
      },
      "source": [
        "Tests for evaluating the implementation of the algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aseXZuL02yf"
      },
      "source": [
        "def test_linear_classifier(dataFun,\n",
        "                           learner,\n",
        "                           learner_params={},\n",
        "                           draw=False,\n",
        "                           refresh=False,\n",
        "                           pause=False):\n",
        "    \"\"\"\n",
        "    Prints score of your classifier on given dataset\n",
        "    dataFun method that returns a dataset\n",
        "    learner your classifier method\n",
        "    learner_params parameters for the learner\n",
        "    \"\"\"\n",
        "    data, labels = dataFun()\n",
        "    d, n = data.shape\n",
        "    if draw:\n",
        "        ax = plot_data(data, labels)\n",
        "\n",
        "        def hook(params):\n",
        "            (th, th0) = params\n",
        "            if refresh: plot_data(data, labels, ax, clear=True)\n",
        "            plot_separator(ax, th, th0)\n",
        "            #print('th', th.T, 'th0', th0)\n",
        "            plt.pause(0.05)\n",
        "            if pause: input('go?')\n",
        "    else:\n",
        "        hook = None\n",
        "    th, th0 = learner(data, labels, hook=hook, params=learner_params)\n",
        "    print(\"Final score\", float(score(data, labels, th, th0)) / n)\n",
        "    print(\"Params\", np.transpose(th), th0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bhI4dQB1-UZ"
      },
      "source": [
        "# <section>**2) Implement perceptron**</section>\n",
        "\n",
        "Implement the perceptron algorithm, where\n",
        "\n",
        "* `data` is a numpy array of dimension $d$ by $n$\n",
        "* `labels` is numpy array of dimension $1$ by $n$\n",
        "* `params` is a dictionary specifying extra parameters to this algorithm; your algorithm should run a number of iterations equal to $T$\n",
        "* `hook` is either None or a function that takes the tuple `(th, th0)` as an argument and displays the separator graphically. \n",
        "\n",
        "It should return a tuple of $\\theta$ (a $d$ by 1 array) and $\\theta_0$ (a 1 by 1 array).\n",
        "\n",
        "Your function should initialize all parameters to 0, then run through the data, in the order it is given, performing an update to the parameters whenever the current parameters would make a mistake on that data point. Perform $T$ iterations through the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtYf8ysk-VQU"
      },
      "source": [
        "def perceptron(data, labels, params = {}, hook = None):    \n",
        "    # if T not in params, default to 100\n",
        "    T = params.get('T', 100)\n",
        "    \n",
        "    # Your implementation here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cGMMVCB1zUc"
      },
      "source": [
        "Test the implementation of perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-fMqXHT1S6c"
      },
      "source": [
        "expected_perceptron = [(np.array([[-9.0], [18.0]]), np.array([[2.0]])),\n",
        "                       (np.array([[0.0], [-3.0]]), np.array([[0.0]]))]\n",
        "expected_averaged = [(np.array([[-9.0525], [17.5825]]), np.array([[1.9425]])),\n",
        "                     (np.array([[1.47], [-1.7275]]), np.array([[0.985]]))]\n",
        "datasets = [super_simple_separable_through_origin, xor]\n",
        "\n",
        "def incorrect(expected, result):\n",
        "    print(\"Test Failed.\")\n",
        "    print(\"Your code output \", result)\n",
        "    print(\"Expected \", expected)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def correct():\n",
        "    print(\"Passed! \\n\")\n",
        "\n",
        "def test_perceptron(perceptron):\n",
        "    \"\"\"\n",
        "    Checks perceptron theta and theta0 values for 100 iterations\n",
        "    \"\"\"\n",
        "    for index in range(len(datasets)):\n",
        "        data, labels = datasets[index]()\n",
        "        th, th0 = perceptron(data, labels, {\"T\": 100})\n",
        "        expected_th, expected_th0 = expected_perceptron[index]\n",
        "        print(\"-----------Test Perceptron \" + str(index) + \"-----------\")\n",
        "        if ((th == expected_th).all() and (th0 == expected_th0).all()):\n",
        "            correct()\n",
        "        else:\n",
        "            incorrect(\n",
        "                \"th: \" + str(expected_th.tolist()) + \", th0: \" +\n",
        "                str(expected_th0.tolist()),\n",
        "                \"th: \" + str(th.tolist()) + \", th0: \" + str(th0.tolist()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92r2oL42-yfM"
      },
      "source": [
        "test_perceptron(perceptron)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQMcSWlmB4-Y"
      },
      "source": [
        "# <section>3) Implement averaged perceptron</section>\n",
        "\n",
        "Regular perceptron can be somewhat sensitive to the most recent examples that it sees. Instead, averaged perceptron produces a more stable output by outputting the average value of `th` and `th0` across all iterations.\n",
        "\n",
        "Implement averaged perceptron with the same spec as regular perceptron, and using the pseudocode below as a guide.\n",
        "<pre>\n",
        "procedure averaged_perceptron({(x^(i), y^(i)), i=1,...n}, T)\n",
        "    th = 0 (d by 1); th0 = 0 (1 by 1)\n",
        "    ths = 0 (d by 1); th0s = 0 (1 by 1)\n",
        "    for t = 1,...,T do:\n",
        "        for i = 1,...,n do:\n",
        "\t        if y^(i)(th . x^(i) + th0) <= 0 then\n",
        "              th = th + y^(i)x^(i)\n",
        "              th0 = th0 + y^(i)\n",
        "\t        ths = ths + th\n",
        "\t        th0s = th0s + th0\n",
        "    return ths/(nT), th0s/(nT)\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAwW00MU_FzS"
      },
      "source": [
        "def averaged_perceptron(data, labels, params={}, hook=None):\n",
        "    # if T not in params, default to 100\n",
        "    T = params.get('T', 100)\n",
        "\n",
        "    # Your implementation here\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3iFRa-m4UsP"
      },
      "source": [
        "Test the implementation of averaged perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWokbXs4YJ8"
      },
      "source": [
        "expected_perceptron = [(np.array([[-9.0], [18.0]]), np.array([[2.0]])),\n",
        "                       (np.array([[0.0], [-3.0]]), np.array([[0.0]]))]\n",
        "expected_averaged = [(np.array([[-9.0525], [17.5825]]), np.array([[1.9425]])),\n",
        "                     (np.array([[1.47], [-1.7275]]), np.array([[0.985]]))]\n",
        "datasets = [super_simple_separable_through_origin, xor]\n",
        "\n",
        "def incorrect(expected, result):\n",
        "    print(\"Test Failed.\")\n",
        "    print(\"Your code output \", result)\n",
        "    print(\"Expected \", expected)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def correct():\n",
        "    print(\"Passed! \\n\")\n",
        "\n",
        "def test_averaged_perceptron(averaged_perceptron):\n",
        "    \"\"\"\n",
        "    Checks average perceptron theta and theta0 values for 100 iterations\n",
        "    \"\"\"\n",
        "    for index in range(2):\n",
        "        data, labels = datasets[index]()\n",
        "        th, th0 = averaged_perceptron(data, labels, {\"T\": 100})\n",
        "        expected_th, expected_th0 = expected_averaged[index]\n",
        "        print(\"-----------Test Averaged Perceptron \" + str(index) +\n",
        "              \"-----------\")\n",
        "        if ((th == expected_th).all() and (th0 == expected_th0).all()):\n",
        "            correct()\n",
        "        else:\n",
        "            incorrect(\n",
        "                \"th: \" + str(expected_th.tolist()) + \", th0: \" +\n",
        "                str(expected_th0.tolist()),\n",
        "                \"th: \" + str(th.tolist()) + \", th0: \" + str(th0.tolist()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyLGH0_cBFSU"
      },
      "source": [
        "test_averaged_perceptron(averaged_perceptron)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTfGq7LNGceQ"
      },
      "source": [
        "# 4) Implement evaluation strategies\n",
        "  \n",
        "## 4.1)  Evaluating a classifier\n",
        "\n",
        "To evaluate a classifier, we are interested in how well it performs on data that it wasn't trained on. Construct a testing procedure that uses a training data set, calls a learning algorithm to get a linear separator (a tuple of $\\theta, \\theta_0$), and then reports the percentage correct on a new testing set as a float between 0. and 1..\n",
        "\n",
        "The learning algorithm is passed as a function that takes a data array and a labels vector.  Your evaluator should be able to interchangeably evaluate `perceptron` or `averaged_perceptron` (or future algorithms with the same spec), depending on what is passed through the `learner` parameter.\n",
        "\n",
        "The `eval_classifier` function should accept the following parameters:\n",
        "\n",
        "* <tt>learner</tt> - a function, such as perceptron or averaged_perceptron\n",
        "* <tt>data_train</tt> - training data\n",
        "* <tt>labels_train</tt> - training labels\n",
        "* <tt>data_test</tt> - test data\n",
        "* <tt>labels_test</tt> - test labels\n",
        "\n",
        "Assume that you have available the function `score`, which takes inputs:\n",
        "\n",
        "* <tt>data</tt>: a <tt>d</tt> by <tt>n</tt> array of floats (representing <tt>n</tt> data points in <tt>d</tt> dimensions)\n",
        "* <tt>labels</tt>: a <tt>1</tt> by <tt>n</tt> array of elements in <tt>(+1, -1)</tt>, representing target labels\n",
        "* <tt>th</tt>: a <tt>d</tt> by <tt>1</tt> array of floats that together with\n",
        "* <tt>th0</tt>: a single scalar or 1 by 1 array, represents a hyperplane\n",
        "\n",
        "and returns 1 by 1 matrix with an integer indicating number of data points correct for the separator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSip1lfHBKaT"
      },
      "source": [
        "def eval_classifier(learner, data_train, labels_train, data_test, labels_test):\n",
        "\n",
        "  # Your implementation here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTTMWPaZ5mS_"
      },
      "source": [
        "Checks your classifier's performance on test data 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzmqEkQ45vzY"
      },
      "source": [
        "def incorrect(expected, result):\n",
        "    print(\"Test Failed.\")\n",
        "    print(\"Your code output \", result)\n",
        "    print(\"Expected \", expected)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def correct():\n",
        "    print(\"Passed! \\n\")\n",
        "\n",
        "def test_eval_classifier(eval_classifier, perceptron):\n",
        "    \"\"\"\n",
        "    Checks your classifier's performance on data1\n",
        "    \"\"\"\n",
        "    expected = [0.5333333333333333, 0.6333333333333333]\n",
        "    dataset_train = [(data1, labels1), (data2, labels2)]\n",
        "    for index in range(len(dataset_train)):\n",
        "        data_train, labels_train = dataset_train[index]\n",
        "        #print(data_train,labels_train)\n",
        "        result = eval_classifier(perceptron, data_train, labels_train, data2,\n",
        "                                 labels2)\n",
        "        print(\"-----------Test Eval Classifier \" + str(index) + \"-----------\")\n",
        "        if (result == expected[index]):\n",
        "            correct()\n",
        "        else:\n",
        "            incorrect(expected[index], result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beHMGAb6BTu1"
      },
      "source": [
        "test_eval_classifier(eval_classifier,perceptron)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WPStky3GiJb"
      },
      "source": [
        "## <subsection>4.2) Evaluating a learning algorithm using a data source</subsection>\n",
        "\n",
        "Construct a testing procedure that takes a learning algorithm and a data source as input and runs the learning algorithm multiple times, each time evaluating the resulting classifier as above. It should report the overall average classification accuracy.\n",
        "\n",
        "You can use our implementation of `eval_classifier` as above.\n",
        "\n",
        "Write the function `eval_learning_alg` that takes:\n",
        "\n",
        "* <tt>learner</tt> - a function, such as perceptron or averaged_perceptron\n",
        "* <tt>data_gen</tt> - a data generator, call it with a desired data set size; returns a tuple (data, labels)\n",
        "* <tt>n_train</tt> - the size of the learning sets\n",
        "* <tt>n_test</tt> - the size of the test sets\n",
        "* <tt>it</tt> - the number of iterations to average over\n",
        "\n",
        "and returns the average classification accuracy as a float between 0. and 1..  \n",
        "\n",
        "** Note: Be sure to generate your training data and then testing data in that order, to ensure that the pseudorandomly generated data matches that in the test code. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qytb8giBXZq"
      },
      "source": [
        "def eval_learning_alg(learner, data_gen, n_train, n_test, it):\n",
        "\n",
        "  # Your implementation here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsOsyGBb6FA7"
      },
      "source": [
        "Tests your classifier's performance on big_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmPwBKnJ6Nds"
      },
      "source": [
        "def incorrect(expected, result):\n",
        "    print(\"Test Failed.\")\n",
        "    print(\"Your code output \", result)\n",
        "    print(\"Expected \", expected)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def correct():\n",
        "    print(\"Passed! \\n\")\n",
        "\n",
        "def test_eval_learning_alg(eval_learning_alg, perceptron):\n",
        "    \"\"\"\n",
        "    Checks your learning algorithm's performance on big_data\n",
        "    eval_learning_alg method for evaluating learning algorithm\n",
        "    perceptron your perceptron learning algorithm method\n",
        "    \"\"\"\n",
        "    expected = 0.5599999999999999\n",
        "    result = eval_learning_alg(perceptron, gen_big_data(), 10, 10, 5)\n",
        "    print(\"-----------Test Eval Learning Algo-----------\")\n",
        "    if result == expected:\n",
        "        correct()\n",
        "    else:\n",
        "        incorrect(expected, result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCZojUBJBb06"
      },
      "source": [
        "test_eval_learning_alg(eval_learning_alg,perceptron)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60u9G0QnGzv-"
      },
      "source": [
        "## <subsection>4.3) Evaluating a learning algorithm with a fixed dataset</subsection>\n",
        "\n",
        "Cross-validation is a strategy for evaluating a learning algorithm, using a single training set of size $n$. Cross-validation takes in a learning algorithm $L$, a fixed data set $\\mathcal{D}$, and a parameter $k$. It will run the learning algorithm $k$ different times, then evaluate the accuracy of the resulting classifier, and ultimately return the average of the accuracies over each of the $k$ \"runs\" of $L$. It is structured like this:\n",
        "\n",
        "<pre><code>divide D into k parts, as equally as possible;  call them D_i for i == 0 .. k-1\n",
        "# be sure the data is shuffled in case someone put all the positive examples first in the data!\n",
        "for j from 0 to k-1:\n",
        "    D_minus_j = union of all the datasets D_i, except for D_j\n",
        "    h_j = L(D_minus_j)\n",
        "    score_j = accuracy of h_j measured on D_j\n",
        "return average(score0, ..., score(k-1))\n",
        "</code></pre>\n",
        "\n",
        "So, each time, it trains on  $kâˆ’1$ of the pieces of the data set and tests the resulting hypothesis on the piece that was not used for training.\n",
        "\n",
        "When $k=n$, it is called *leave-one-out cross validation*.\n",
        "\n",
        "Implement cross validation **assuming that the input data is shuffled already** so that the positives and negatives are distributed randomly. If the size of the data does not evenly divide by k, split the data into n % k sub-arrays of size n//k + 1 and the rest of size n//k. (Hint: You can use <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.array_split.html\">numpy.array_split</a>\n",
        "and <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html\">numpy.concatenate</a> with axis arguments to split and rejoin the data as you desire.)\n",
        "\n",
        "Note: In Python, n//k indicates integer division, e.g. 2//3 gives 0 and 4//3 gives 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5_iixOmBgR7"
      },
      "source": [
        "def xval_learning_alg(learner, data, labels, k):\n",
        "\n",
        "  # Your implementation here\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs26YFWI6oHB"
      },
      "source": [
        "Checks your classifier's performance on big_data using cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVdfS2hB6w5w"
      },
      "source": [
        "def incorrect(expected, result):\n",
        "    print(\"Test Failed.\")\n",
        "    print(\"Your code output \", result)\n",
        "    print(\"Expected \", expected)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def correct():\n",
        "    print(\"Passed! \\n\")\n",
        "\n",
        "def test_xval_learning_alg(xval_learning_alg, perceptron):\n",
        "    '''\n",
        "    Checks your learning algorithm's performance on big_data using cross validation\n",
        "    xval_learning_alg method for evaluating learning algorithm using cross validation\n",
        "    perceptron your perceptron learning algorithm method\n",
        "    '''\n",
        "    expected = 0.61\n",
        "    result = xval_learning_alg(perceptron, big_data, big_data_labels, 5)\n",
        "    print(\"-----------Test Cross-eval Learning Algo-----------\")\n",
        "    if result == expected:\n",
        "        correct()\n",
        "    else:\n",
        "        incorrect(expected, result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUiUgtMHBiZX"
      },
      "source": [
        "test_xval_learning_alg(xval_learning_alg,perceptron)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crF8flfB3hr1"
      },
      "source": [
        "## 5) Testing\n",
        "\n",
        "In this section, we compare the effectiveness of perceptron and averaged perceptron on some data that are not necessarily linearly separable.\n",
        "\n",
        "Use your `eval_learning_alg` and the `gen_flipped_lin_separable` generator to evaluate the accuracy of `perceptron` vs. `averaged_perceptron`. `gen_flipped_lin_separable` can be called with an integer to return a data set and labels. Note that this generates linearly separable data and then \"flips\" the labels with some specified probability (the argument pflip); so most of the results will not be linearly separable. You can also specifiy pflip in the call to the generator. You should use the default values of th and th_0 for the evaluation functions to run correctly.\n",
        "\n",
        "Run enough trials so that you can confidently predict the accuracy of these algorithms on new data from that same generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXFoptqiI6Aw"
      },
      "source": [
        "print(eval_learning_alg(perceptron, gen_flipped_lin_separable(pflip=.1), 20, 20, 5))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}